{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-0YTYX-1Dv0"
      },
      "source": [
        "# **Kaggle ‚Äì DataTops¬Æ**\n",
        "Tu TA ha decidido cambiar de aires y, por eso, ha comprado una tienda de port√°tiles. Sin embargo, su √∫nica especialidad es Data Science, por lo que ha decidido crear un modelo de ML para establecer los mejores precios.\n",
        "\n",
        "¬øPodr√≠as ayudar a tu profe a mejorar ese modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b_oPcSD1Dv3"
      },
      "source": [
        "## Aspectos importantes\n",
        "- √öltima submission:\n",
        "    - Ma√±ana: 17 de febrero a las 5pm\n",
        "    - Tarde: 19 de febrero a las 5pm\n",
        "- **Enlace de la competici√≥n**: https://www.kaggle.com/t/c5cc87b50c4b4770bdc8f5acbe15577d\n",
        "- **Requisito**: Estar registrado en [Kaggle](https://www.kaggle.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLjH6XtL1Dv3"
      },
      "source": [
        "## M√©trica:\n",
        "El error cuadr√°tico medio (RMSE, por sus siglas en ingl√©s) es una medida de la desviaci√≥n est√°ndar de los residuos (errores de predicci√≥n). Los residuos representan la diferencia entre los valores observados y los valores predichos por el modelo. El RMSE indica qu√© tan dispersos est√°n estos errores: cuanto menor es el RMSE, m√°s cercanas est√°n las predicciones a los valores reales. En otras palabras, el RMSE mide qu√© tan bien se ajusta la l√≠nea de regresi√≥n a los datos.\n",
        "\n",
        "\n",
        "$$ RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(\\frac{d_i -f_i}{\\sigma_i}\\Big)^2}}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsfzFSuz1Dv4"
      },
      "source": [
        "## 1. Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EW6W1-bd1Dv4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Oxf5-2G1Dv5"
      },
      "source": [
        "## 2. Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0r1O0xvP1Dv5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "PASO 1: CARGA DE DATOS\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Datos cargados:\n",
            "   train: (912, 13) (CON precio)\n",
            "   test: (391, 12) (SIN precio)\n",
            "   sample_submission: (391, 2)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PASO 1: CARGAR DATOS (CORRECTAMENTE)\n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"PASO 1: CARGA DE DATOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cargar archivos\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
        "\n",
        "print(f\"\\n‚úÖ Datos cargados:\")\n",
        "print(f\"   train: {train.shape} (CON precio)\")\n",
        "print(f\"   test: {test.shape} (SIN precio)\")\n",
        "print(f\"   sample_submission: {sample_submission.shape}\")\n",
        "\n",
        "# Copias para procesar\n",
        "train_processed = train.copy()\n",
        "test_processed = test.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybAGcmnO1Dv5"
      },
      "source": [
        "### 2.1 Exploraci√≥n de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iXQUY5DK1Dv5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 912 entries, 0 to 911\n",
            "Data columns (total 13 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   laptop_ID         912 non-null    int64  \n",
            " 1   Company           912 non-null    object \n",
            " 2   Product           912 non-null    object \n",
            " 3   TypeName          912 non-null    object \n",
            " 4   Inches            912 non-null    float64\n",
            " 5   ScreenResolution  912 non-null    object \n",
            " 6   Cpu               912 non-null    object \n",
            " 7   Ram               912 non-null    object \n",
            " 8   Memory            912 non-null    object \n",
            " 9   Gpu               912 non-null    object \n",
            " 10  OpSys             912 non-null    object \n",
            " 11  Weight            912 non-null    object \n",
            " 12  Price_in_euros    912 non-null    float64\n",
            "dtypes: float64(2), int64(1), object(10)\n",
            "memory usage: 92.8+ KB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['laptop_ID', 'Company', 'Product', 'TypeName', 'Inches', 'ScreenResolution', 'Cpu', 'Ram', 'Memory', 'Gpu', 'OpSys', 'Weight', 'Price_in_euros']\n"
          ]
        }
      ],
      "source": [
        "print(train.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BZhmjbtQ1Dv5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>laptop_ID</th>\n",
              "      <th>Company</th>\n",
              "      <th>Product</th>\n",
              "      <th>TypeName</th>\n",
              "      <th>Inches</th>\n",
              "      <th>ScreenResolution</th>\n",
              "      <th>Cpu</th>\n",
              "      <th>Ram</th>\n",
              "      <th>Memory</th>\n",
              "      <th>Gpu</th>\n",
              "      <th>OpSys</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Price_in_euros</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>755</td>\n",
              "      <td>HP</td>\n",
              "      <td>250 G6</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>15.6</td>\n",
              "      <td>Full HD 1920x1080</td>\n",
              "      <td>Intel Core i3 6006U 2GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>256GB SSD</td>\n",
              "      <td>Intel HD Graphics 520</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>1.86kg</td>\n",
              "      <td>539.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>618</td>\n",
              "      <td>Dell</td>\n",
              "      <td>Inspiron 7559</td>\n",
              "      <td>Gaming</td>\n",
              "      <td>15.6</td>\n",
              "      <td>Full HD 1920x1080</td>\n",
              "      <td>Intel Core i7 6700HQ 2.6GHz</td>\n",
              "      <td>16GB</td>\n",
              "      <td>1TB HDD</td>\n",
              "      <td>Nvidia GeForce GTX 960&lt;U+039C&gt;</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.59kg</td>\n",
              "      <td>879.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>909</td>\n",
              "      <td>HP</td>\n",
              "      <td>ProBook 450</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>15.6</td>\n",
              "      <td>Full HD 1920x1080</td>\n",
              "      <td>Intel Core i7 7500U 2.7GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>1TB HDD</td>\n",
              "      <td>Nvidia GeForce 930MX</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.04kg</td>\n",
              "      <td>900.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Macbook Air</td>\n",
              "      <td>Ultrabook</td>\n",
              "      <td>13.3</td>\n",
              "      <td>1440x900</td>\n",
              "      <td>Intel Core i5 1.8GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>128GB Flash Storage</td>\n",
              "      <td>Intel HD Graphics 6000</td>\n",
              "      <td>macOS</td>\n",
              "      <td>1.34kg</td>\n",
              "      <td>898.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>286</td>\n",
              "      <td>Dell</td>\n",
              "      <td>Inspiron 3567</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>15.6</td>\n",
              "      <td>Full HD 1920x1080</td>\n",
              "      <td>Intel Core i3 6006U 2.0GHz</td>\n",
              "      <td>4GB</td>\n",
              "      <td>1TB HDD</td>\n",
              "      <td>AMD Radeon R5 M430</td>\n",
              "      <td>Linux</td>\n",
              "      <td>2.25kg</td>\n",
              "      <td>428.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   laptop_ID Company        Product   TypeName  Inches   ScreenResolution  \\\n",
              "0        755      HP         250 G6   Notebook    15.6  Full HD 1920x1080   \n",
              "1        618    Dell  Inspiron 7559     Gaming    15.6  Full HD 1920x1080   \n",
              "2        909      HP    ProBook 450   Notebook    15.6  Full HD 1920x1080   \n",
              "3          2   Apple    Macbook Air  Ultrabook    13.3           1440x900   \n",
              "4        286    Dell  Inspiron 3567   Notebook    15.6  Full HD 1920x1080   \n",
              "\n",
              "                           Cpu   Ram               Memory  \\\n",
              "0     Intel Core i3 6006U 2GHz   8GB            256GB SSD   \n",
              "1  Intel Core i7 6700HQ 2.6GHz  16GB              1TB HDD   \n",
              "2   Intel Core i7 7500U 2.7GHz   8GB              1TB HDD   \n",
              "3         Intel Core i5 1.8GHz   8GB  128GB Flash Storage   \n",
              "4   Intel Core i3 6006U 2.0GHz   4GB              1TB HDD   \n",
              "\n",
              "                              Gpu       OpSys  Weight  Price_in_euros  \n",
              "0           Intel HD Graphics 520  Windows 10  1.86kg          539.00  \n",
              "1  Nvidia GeForce GTX 960<U+039C>  Windows 10  2.59kg          879.01  \n",
              "2            Nvidia GeForce 930MX  Windows 10  2.04kg          900.00  \n",
              "3          Intel HD Graphics 6000       macOS  1.34kg          898.94  \n",
              "4              AMD Radeon R5 M430       Linux  2.25kg          428.00  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ihQFi2H21Dv5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>laptop_ID</th>\n",
              "      <th>Company</th>\n",
              "      <th>Product</th>\n",
              "      <th>TypeName</th>\n",
              "      <th>Inches</th>\n",
              "      <th>ScreenResolution</th>\n",
              "      <th>Cpu</th>\n",
              "      <th>Ram</th>\n",
              "      <th>Memory</th>\n",
              "      <th>Gpu</th>\n",
              "      <th>OpSys</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Price_in_euros</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>28</td>\n",
              "      <td>Dell</td>\n",
              "      <td>Inspiron 5570</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>15.6</td>\n",
              "      <td>Full HD 1920x1080</td>\n",
              "      <td>Intel Core i5 8250U 1.6GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>256GB SSD</td>\n",
              "      <td>AMD Radeon 530</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.2kg</td>\n",
              "      <td>800.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>1160</td>\n",
              "      <td>HP</td>\n",
              "      <td>Spectre Pro</td>\n",
              "      <td>2 in 1 Convertible</td>\n",
              "      <td>13.3</td>\n",
              "      <td>Full HD / Touchscreen 1920x1080</td>\n",
              "      <td>Intel Core i5 6300U 2.4GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>256GB SSD</td>\n",
              "      <td>Intel HD Graphics 520</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>1.48kg</td>\n",
              "      <td>1629.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>78</td>\n",
              "      <td>Lenovo</td>\n",
              "      <td>IdeaPad 320-15IKBN</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>15.6</td>\n",
              "      <td>Full HD 1920x1080</td>\n",
              "      <td>Intel Core i5 7200U 2.5GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>2TB HDD</td>\n",
              "      <td>Intel HD Graphics 620</td>\n",
              "      <td>No OS</td>\n",
              "      <td>2.2kg</td>\n",
              "      <td>519.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>910</th>\n",
              "      <td>23</td>\n",
              "      <td>HP</td>\n",
              "      <td>255 G6</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>15.6</td>\n",
              "      <td>1366x768</td>\n",
              "      <td>AMD E-Series E2-9000e 1.5GHz</td>\n",
              "      <td>4GB</td>\n",
              "      <td>500GB HDD</td>\n",
              "      <td>AMD Radeon R2</td>\n",
              "      <td>No OS</td>\n",
              "      <td>1.86kg</td>\n",
              "      <td>258.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>229</td>\n",
              "      <td>Dell</td>\n",
              "      <td>Alienware 17</td>\n",
              "      <td>Gaming</td>\n",
              "      <td>17.3</td>\n",
              "      <td>IPS Panel Full HD 1920x1080</td>\n",
              "      <td>Intel Core i7 7700HQ 2.8GHz</td>\n",
              "      <td>16GB</td>\n",
              "      <td>256GB SSD +  1TB HDD</td>\n",
              "      <td>Nvidia GeForce GTX 1060</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>4.42kg</td>\n",
              "      <td>2456.34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     laptop_ID Company             Product            TypeName  Inches  \\\n",
              "907         28    Dell       Inspiron 5570            Notebook    15.6   \n",
              "908       1160      HP         Spectre Pro  2 in 1 Convertible    13.3   \n",
              "909         78  Lenovo  IdeaPad 320-15IKBN            Notebook    15.6   \n",
              "910         23      HP              255 G6            Notebook    15.6   \n",
              "911        229    Dell        Alienware 17              Gaming    17.3   \n",
              "\n",
              "                    ScreenResolution                           Cpu   Ram  \\\n",
              "907                Full HD 1920x1080    Intel Core i5 8250U 1.6GHz   8GB   \n",
              "908  Full HD / Touchscreen 1920x1080    Intel Core i5 6300U 2.4GHz   8GB   \n",
              "909                Full HD 1920x1080    Intel Core i5 7200U 2.5GHz   8GB   \n",
              "910                         1366x768  AMD E-Series E2-9000e 1.5GHz   4GB   \n",
              "911      IPS Panel Full HD 1920x1080   Intel Core i7 7700HQ 2.8GHz  16GB   \n",
              "\n",
              "                   Memory                      Gpu       OpSys  Weight  \\\n",
              "907             256GB SSD           AMD Radeon 530  Windows 10   2.2kg   \n",
              "908             256GB SSD    Intel HD Graphics 520  Windows 10  1.48kg   \n",
              "909               2TB HDD    Intel HD Graphics 620       No OS   2.2kg   \n",
              "910             500GB HDD            AMD Radeon R2       No OS  1.86kg   \n",
              "911  256GB SSD +  1TB HDD  Nvidia GeForce GTX 1060  Windows 10  4.42kg   \n",
              "\n",
              "     Price_in_euros  \n",
              "907          800.00  \n",
              "908         1629.00  \n",
              "909          519.00  \n",
              "910          258.00  \n",
              "911         2456.34  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O9TDfZEt1Dv5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>laptop_ID</th>\n",
              "      <th>Inches</th>\n",
              "      <th>Price_in_euros</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>912.000000</td>\n",
              "      <td>912.000000</td>\n",
              "      <td>912.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>650.312500</td>\n",
              "      <td>14.981579</td>\n",
              "      <td>1111.724090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>382.727748</td>\n",
              "      <td>1.436719</td>\n",
              "      <td>687.959172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>10.100000</td>\n",
              "      <td>174.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>324.750000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>589.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>636.500000</td>\n",
              "      <td>15.600000</td>\n",
              "      <td>978.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>982.250000</td>\n",
              "      <td>15.600000</td>\n",
              "      <td>1483.942500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1320.000000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>6099.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         laptop_ID      Inches  Price_in_euros\n",
              "count   912.000000  912.000000      912.000000\n",
              "mean    650.312500   14.981579     1111.724090\n",
              "std     382.727748    1.436719      687.959172\n",
              "min       2.000000   10.100000      174.000000\n",
              "25%     324.750000   14.000000      589.000000\n",
              "50%     636.500000   15.600000      978.000000\n",
              "75%     982.250000   15.600000     1483.942500\n",
              "max    1320.000000   18.400000     6099.000000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç VALORES NULOS EN TRAIN:\n",
            "   ‚úÖ No hay valores nulos\n",
            "\n",
            "üîç VALORES NULOS EN TEST:\n",
            "   ‚úÖ No hay valores nulos\n",
            "\n",
            "üìä TIPOS DE COLUMNAS:\n",
            "\n",
            "   Num√©ricas (3):\n",
            "      - laptop_ID\n",
            "      - Inches\n",
            "      - Price_in_euros\n",
            "\n",
            "   Categ√≥ricas (10):\n",
            "      - Company                        (19 valores √∫nicos)\n",
            "      - Product                        (480 valores √∫nicos)\n",
            "      - TypeName                       (6 valores √∫nicos)\n",
            "      - ScreenResolution               (36 valores √∫nicos)\n",
            "      - Cpu                            (107 valores √∫nicos)\n",
            "      - Ram                            (9 valores √∫nicos)\n",
            "      - Memory                         (37 valores √∫nicos)\n",
            "      - Gpu                            (93 valores √∫nicos)\n",
            "      - OpSys                          (9 valores √∫nicos)\n",
            "      - Weight                         (165 valores √∫nicos)\n"
          ]
        }
      ],
      "source": [
        "# Valores nulos\n",
        "print(\"\\n VALORES NULOS EN TRAIN:\")\n",
        "nulos_train = train.isnull().sum()\n",
        "if nulos_train.sum() > 0:\n",
        "    print(nulos_train[nulos_train > 0].sort_values(ascending=False))\n",
        "else:\n",
        "    print(\"    No hay valores nulos\")\n",
        "\n",
        "print(\"\\n VALORES NULOS EN TEST:\")\n",
        "nulos_test = test.isnull().sum()\n",
        "if nulos_test.sum() > 0:\n",
        "    print(nulos_test[nulos_test > 0].sort_values(ascending=False))\n",
        "else:\n",
        "    print(\"    No hay valores nulos\")\n",
        "\n",
        "# Tipos de columnas\n",
        "print(\"\\n TIPOS DE COLUMNAS:\")\n",
        "numeric_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Excluir id y target\n",
        "if 'id' in numeric_cols:\n",
        "    numeric_cols.remove('id')\n",
        "if 'Price_euros' in numeric_cols:\n",
        "    numeric_cols.remove('Price_euros')\n",
        "\n",
        "print(f\"\\n   Num√©ricas ({len(numeric_cols)}):\")\n",
        "for col in numeric_cols:\n",
        "    print(f\"      - {col}\")\n",
        "\n",
        "print(f\"\\n   Categ√≥ricas ({len(categorical_cols)}):\")\n",
        "for col in categorical_cols:\n",
        "    n_unique = train[col].nunique()\n",
        "    print(f\"      - {col:30s} ({n_unique} valores √∫nicos)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "PASO 2: FEATURE ENGINEERING\n",
            "======================================================================\n",
            "\n",
            "üîß PROCESAMIENTO DE FEATURES...\n",
            "\n",
            "1Ô∏è‚É£ Procesando RAM...\n",
            "   ‚úÖ Ram original: ['8GB', '16GB', '8GB']\n",
            "   ‚úÖ Ram_GB: [8, 16, 8]\n",
            "\n",
            "2Ô∏è‚É£ Procesando Weight...\n",
            "   ‚úÖ Weight original: ['1.86kg', '2.59kg', '2.04kg']\n",
            "   ‚úÖ Weight_kg: [1.86, 2.59, 2.04]\n",
            "\n",
            "3Ô∏è‚É£ Procesando Memory...\n",
            "   ‚úÖ Memory original: ['256GB SSD', '1TB HDD', '1TB HDD']\n",
            "   ‚úÖ Memory_GB: [256.0, 1024.0, 1024.0]\n",
            "   ‚úÖ Has_SSD: [1, 0, 0]\n",
            "   ‚úÖ Has_HDD: [0, 1, 1]\n",
            "\n",
            "4Ô∏è‚É£ Procesando ScreenResolution...\n",
            "   ‚úÖ ScreenResolution original: ['Full HD 1920x1080', 'Full HD 1920x1080']\n",
            "   ‚úÖ Screen_Pixels: [nan, nan]\n",
            "   ‚úÖ Is_Touchscreen: [0, 0]\n",
            "\n",
            "5Ô∏è‚É£ Procesando CPU...\n",
            "   ‚úÖ CPU original: ['Intel Core i3 6006U 2GHz', 'Intel Core i7 6700HQ 2.6GHz']\n",
            "   ‚úÖ CPU_Brand: ['Intel_i3', 'Intel_i7']\n",
            "\n",
            "6Ô∏è‚É£ Procesando GPU...\n",
            "   ‚úÖ GPU original: ['Intel HD Graphics 520', 'Nvidia GeForce GTX 960<U+039C>']\n",
            "   ‚úÖ GPU_Brand: ['Intel', 'Nvidia']\n",
            "\n",
            "‚úÖ FEATURE ENGINEERING COMPLETADO\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"PASO 2: FEATURE ENGINEERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Hacer copias para no modificar originales\n",
        "train_processed = train.copy()\n",
        "test_processed = test.copy()\n",
        "\n",
        "print(\"\\nüîß PROCESAMIENTO DE FEATURES...\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. RAM: Convertir \"8GB\" ‚Üí 8\n",
        "# ============================================================================\n",
        "print(\"\\n1Ô∏è‚É£ Procesando RAM...\")\n",
        "\n",
        "def extract_ram(ram_str):\n",
        "    \"\"\"Extrae n√∫mero de GB de RAM. Ejemplo: '8GB' ‚Üí 8\"\"\"\n",
        "    if pd.isna(ram_str):\n",
        "        return np.nan\n",
        "    # Extraer n√∫meros\n",
        "    import re\n",
        "    numbers = re.findall(r'\\d+', str(ram_str))\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    return np.nan\n",
        "\n",
        "train_processed['Ram_GB'] = train_processed['Ram'].apply(extract_ram)\n",
        "test_processed['Ram_GB'] = test_processed['Ram'].apply(extract_ram)\n",
        "\n",
        "print(f\"    Ram original: {train['Ram'].head(3).tolist()}\")\n",
        "print(f\"    Ram_GB: {train_processed['Ram_GB'].head(3).tolist()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. WEIGHT: Convertir \"1.86kg\" ‚Üí 1.86\n",
        "# ============================================================================\n",
        "print(\"\\n2Ô∏è Procesando Weight...\")\n",
        "\n",
        "def extract_weight(weight_str):\n",
        "    \"\"\"Extrae peso en kg. Ejemplo: '1.86kg' ‚Üí 1.86\"\"\"\n",
        "    if pd.isna(weight_str):\n",
        "        return np.nan\n",
        "    import re\n",
        "    # Buscar n√∫meros (incluyendo decimales)\n",
        "    numbers = re.findall(r'\\d+\\.?\\d*', str(weight_str))\n",
        "    if numbers:\n",
        "        return float(numbers[0])\n",
        "    return np.nan\n",
        "\n",
        "train_processed['Weight_kg'] = train_processed['Weight'].apply(extract_weight)\n",
        "test_processed['Weight_kg'] = test_processed['Weight'].apply(extract_weight)\n",
        "\n",
        "print(f\"    Weight original: {train['Weight'].head(3).tolist()}\")\n",
        "print(f\"    Weight_kg: {train_processed['Weight_kg'].head(3).tolist()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. MEMORY: Extraer tipo y capacidad\n",
        "# ============================================================================\n",
        "print(\"\\n3Ô∏è Procesando Memory...\")\n",
        "\n",
        "def extract_memory_features(memory_str):\n",
        "    \"\"\"\n",
        "    Extrae caracter√≠sticas de memoria.\n",
        "    Ejemplos:\n",
        "    - '256GB SSD' ‚Üí (256, 1, 0)  # (capacidad, es_ssd, es_hdd)\n",
        "    - '1TB HDD' ‚Üí (1024, 0, 1)\n",
        "    - '128GB SSD +  1TB HDD' ‚Üí (1152, 1, 1)  # H√≠brido\n",
        "    \"\"\"\n",
        "    if pd.isna(memory_str):\n",
        "        return (np.nan, 0, 0)\n",
        "    \n",
        "    memory_str = str(memory_str).upper()\n",
        "    \n",
        "    # Detectar SSD y HDD\n",
        "    has_ssd = 1 if 'SSD' in memory_str else 0\n",
        "    has_hdd = 1 if 'HDD' in memory_str else 0\n",
        "    \n",
        "    # Extraer capacidades\n",
        "    import re\n",
        "    total_gb = 0\n",
        "    \n",
        "    # Buscar patrones como \"256GB\", \"1TB\"\n",
        "    gb_matches = re.findall(r'(\\d+)\\s*GB', memory_str)\n",
        "    tb_matches = re.findall(r'(\\d+)\\s*TB', memory_str)\n",
        "    \n",
        "    for gb in gb_matches:\n",
        "        total_gb += int(gb)\n",
        "    \n",
        "    for tb in tb_matches:\n",
        "        total_gb += int(tb) * 1024\n",
        "    \n",
        "    return (total_gb if total_gb > 0 else np.nan, has_ssd, has_hdd)\n",
        "\n",
        "# Aplicar\n",
        "memory_features = train_processed['Memory'].apply(extract_memory_features)\n",
        "train_processed['Memory_GB'] = [x[0] for x in memory_features]\n",
        "train_processed['Has_SSD'] = [x[1] for x in memory_features]\n",
        "train_processed['Has_HDD'] = [x[2] for x in memory_features]\n",
        "\n",
        "memory_features_test = test_processed['Memory'].apply(extract_memory_features)\n",
        "test_processed['Memory_GB'] = [x[0] for x in memory_features_test]\n",
        "test_processed['Has_SSD'] = [x[1] for x in memory_features_test]\n",
        "test_processed['Has_HDD'] = [x[2] for x in memory_features_test]\n",
        "\n",
        "print(f\"    Memory original: {train['Memory'].head(3).tolist()}\")\n",
        "print(f\"    Memory_GB: {train_processed['Memory_GB'].head(3).tolist()}\")\n",
        "print(f\"    Has_SSD: {train_processed['Has_SSD'].head(3).tolist()}\")\n",
        "print(f\"    Has_HDD: {train_processed['Has_HDD'].head(3).tolist()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. SCREEN RESOLUTION: Extraer resoluci√≥n y tipo\n",
        "# ============================================================================\n",
        "print(\"\\n4Ô∏è‚É£ Procesando ScreenResolution...\")\n",
        "\n",
        "def extract_screen_features(screen_str):\n",
        "    \"\"\"\n",
        "    Extrae caracter√≠sticas de pantalla.\n",
        "    Ejemplos:\n",
        "    - 'Full HD 1920x1080' ‚Üí (1920, 1080, 1, 0)  # (width, height, is_fhd, is_4k)\n",
        "    - '4K Ultra HD 3840x2160' ‚Üí (3840, 2160, 0, 1)\n",
        "    \"\"\"\n",
        "    if pd.isna(screen_str):\n",
        "        return (np.nan, np.nan, 0, 0, 0)\n",
        "    \n",
        "    screen_str = str(screen_str).upper()\n",
        "    \n",
        "    # Detectar tipos\n",
        "    is_touchscreen = 1 if 'TOUCHSCREEN' in screen_str else 0\n",
        "    is_ips = 1 if 'IPS' in screen_str else 0\n",
        "    is_4k = 1 if '4K' in screen_str or '3840' in screen_str else 0\n",
        "    \n",
        "    # Extraer resoluci√≥n (patr√≥n: 1920x1080)\n",
        "    import re\n",
        "    resolution = re.search(r'(\\d+)\\s*x\\s*(\\d+)', screen_str)\n",
        "    \n",
        "    if resolution:\n",
        "        width = int(resolution.group(1))\n",
        "        height = int(resolution.group(2))\n",
        "        total_pixels = width * height\n",
        "    else:\n",
        "        width, height, total_pixels = np.nan, np.nan, np.nan\n",
        "    \n",
        "    return (total_pixels, is_touchscreen, is_ips, is_4k)\n",
        "\n",
        "screen_features = train_processed['ScreenResolution'].apply(extract_screen_features)\n",
        "train_processed['Screen_Pixels'] = [x[0] for x in screen_features]\n",
        "train_processed['Is_Touchscreen'] = [x[1] for x in screen_features]\n",
        "train_processed['Is_IPS'] = [x[2] for x in screen_features]\n",
        "train_processed['Is_4K'] = [x[3] for x in screen_features]\n",
        "\n",
        "screen_features_test = test_processed['ScreenResolution'].apply(extract_screen_features)\n",
        "test_processed['Screen_Pixels'] = [x[0] for x in screen_features_test]\n",
        "test_processed['Is_Touchscreen'] = [x[1] for x in screen_features_test]\n",
        "test_processed['Is_IPS'] = [x[2] for x in screen_features_test]\n",
        "test_processed['Is_4K'] = [x[3] for x in screen_features_test]\n",
        "\n",
        "print(f\"    ScreenResolution original: {train['ScreenResolution'].head(2).tolist()}\")\n",
        "print(f\"    Screen_Pixels: {train_processed['Screen_Pixels'].head(2).tolist()}\")\n",
        "print(f\"    Is_Touchscreen: {train_processed['Is_Touchscreen'].head(2).tolist()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. CPU: Extraer marca y tipo\n",
        "# ============================================================================\n",
        "print(\"\\n5Ô∏è‚É£ Procesando CPU...\")\n",
        "\n",
        "def extract_cpu_brand(cpu_str):\n",
        "    \"\"\"Extrae marca de CPU\"\"\"\n",
        "    if pd.isna(cpu_str):\n",
        "        return 'Unknown'\n",
        "    cpu_str = str(cpu_str).upper()\n",
        "    if 'INTEL CORE I7' in cpu_str:\n",
        "        return 'Intel_i7'\n",
        "    elif 'INTEL CORE I5' in cpu_str:\n",
        "        return 'Intel_i5'\n",
        "    elif 'INTEL CORE I3' in cpu_str:\n",
        "        return 'Intel_i3'\n",
        "    elif 'AMD' in cpu_str:\n",
        "        return 'AMD'\n",
        "    elif 'INTEL' in cpu_str:\n",
        "        return 'Intel_Other'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "train_processed['CPU_Brand'] = train_processed['Cpu'].apply(extract_cpu_brand)\n",
        "test_processed['CPU_Brand'] = test_processed['Cpu'].apply(extract_cpu_brand)\n",
        "\n",
        "print(f\"    CPU original: {train['Cpu'].head(2).tolist()}\")\n",
        "print(f\"    CPU_Brand: {train_processed['CPU_Brand'].head(2).tolist()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. GPU: Extraer marca\n",
        "# ============================================================================\n",
        "print(\"\\n6Ô∏è‚É£ Procesando GPU...\")\n",
        "\n",
        "def extract_gpu_brand(gpu_str):\n",
        "    \"\"\"Extrae marca de GPU\"\"\"\n",
        "    if pd.isna(gpu_str):\n",
        "        return 'Unknown'\n",
        "    gpu_str = str(gpu_str).upper()\n",
        "    if 'NVIDIA' in gpu_str or 'GEFORCE' in gpu_str:\n",
        "        return 'Nvidia'\n",
        "    elif 'AMD' in gpu_str or 'RADEON' in gpu_str:\n",
        "        return 'AMD'\n",
        "    elif 'INTEL' in gpu_str:\n",
        "        return 'Intel'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "train_processed['GPU_Brand'] = train_processed['Gpu'].apply(extract_gpu_brand)\n",
        "test_processed['GPU_Brand'] = test_processed['Gpu'].apply(extract_gpu_brand)\n",
        "\n",
        "print(f\"    GPU original: {train['Gpu'].head(2).tolist()}\")\n",
        "print(f\"    GPU_Brand: {train_processed['GPU_Brand'].head(2).tolist()}\")\n",
        "\n",
        "print(\"\\n FEATURE ENGINEERING COMPLETADO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FEATURE ENGINEERING AVANZADO\n",
            "======================================================================\n",
            "‚úÖ Nuevas features creadas\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lupep\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1213: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "C:\\Users\\lupep\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1213: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"FEATURE ENGINEERING AVANZADO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Aplicar a train y test\n",
        "for df in [train_processed, test_processed]:\n",
        "    \n",
        "    # 1. PPI (Pixels Per Inch)\n",
        "    df['PPI'] = df['Screen_Pixels'] / (df['Inches'] ** 2)\n",
        "    df['PPI'] = df['PPI'].fillna(df['PPI'].median())\n",
        "    \n",
        "    # 2. RAM por peso\n",
        "    df['RAM_per_Weight'] = df['Ram_GB'] / df['Weight_kg']\n",
        "    df['RAM_per_Weight'] = df['RAM_per_Weight'].fillna(df['RAM_per_Weight'].median())\n",
        "    \n",
        "    # 3. Storage por peso\n",
        "    df['Storage_per_Weight'] = df['Memory_GB'] / df['Weight_kg']\n",
        "    df['Storage_per_Weight'] = df['Storage_per_Weight'].fillna(df['Storage_per_Weight'].median())\n",
        "    \n",
        "    # 4. Total de recursos\n",
        "    df['Total_Resources'] = df['Ram_GB'] + (df['Memory_GB'] / 100)\n",
        "    \n",
        "    # 5. Es gaming\n",
        "    df['Is_Gaming'] = ((df['GPU_Brand'] == 'Nvidia') & (df['Ram_GB'] >= 8)).astype(int)\n",
        "    \n",
        "    # 6. Es premium\n",
        "    df['Is_Premium'] = (\n",
        "        (df['Company'] == 'Apple') | \n",
        "        ((df['Ram_GB'] >= 16) & (df['Has_SSD'] == 1))\n",
        "    ).astype(int)\n",
        "    \n",
        "    # 7. Interacci√≥n RAM x Storage\n",
        "    df['RAM_x_Storage'] = df['Ram_GB'] * np.log1p(df['Memory_GB'])\n",
        "    df['RAM_x_Storage'] = df['RAM_x_Storage'].fillna(df['RAM_x_Storage'].median())\n",
        "\n",
        "print(\"‚úÖ Nuevas features creadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VERIFICACI√ìN DE NUEVAS FEATURES\n",
            "======================================================================\n",
            "\n",
            "üìä NUEVAS FEATURES NUM√âRICAS:\n",
            "           Ram_GB   Weight_kg    Memory_GB     Has_SSD     Has_HDD  \\\n",
            "count  912.000000  912.000000   906.000000  912.000000  912.000000   \n",
            "mean     8.263158    2.026937   602.388521    0.643640    0.434211   \n",
            "std      5.044788    0.665466   471.401399    0.479186    0.495925   \n",
            "min      2.000000    0.690000     8.000000    0.000000    0.000000   \n",
            "25%      4.000000    1.490000   256.000000    0.000000    0.000000   \n",
            "50%      8.000000    2.040000   500.000000    1.000000    0.000000   \n",
            "75%      8.000000    2.300000  1024.000000    1.000000    1.000000   \n",
            "max     64.000000    4.700000  2560.000000    1.000000    1.000000   \n",
            "\n",
            "       Screen_Pixels  Is_Touchscreen      Is_IPS       Is_4K  \n",
            "count            0.0      912.000000  912.000000  912.000000  \n",
            "mean             NaN        0.143640    0.275219    0.028509  \n",
            "std              NaN        0.350917    0.446870    0.166513  \n",
            "min              NaN        0.000000    0.000000    0.000000  \n",
            "25%              NaN        0.000000    0.000000    0.000000  \n",
            "50%              NaN        0.000000    0.000000    0.000000  \n",
            "75%              NaN        0.000000    1.000000    0.000000  \n",
            "max              NaN        1.000000    1.000000    1.000000  \n",
            "\n",
            "üìä NUEVAS FEATURES CATEG√ìRICAS:\n",
            "\n",
            "CPU_Brand:\n",
            "CPU_Brand\n",
            "Intel_i7       374\n",
            "Intel_i5       282\n",
            "Intel_Other    121\n",
            "Intel_i3        93\n",
            "AMD             42\n",
            "Name: count, dtype: int64\n",
            "\n",
            "GPU_Brand:\n",
            "GPU_Brand\n",
            "Intel     509\n",
            "Nvidia    284\n",
            "AMD       119\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VERIFICACI√ìN DE NUEVAS FEATURES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Ver nuevas columnas num√©ricas\n",
        "nuevas_numericas = ['Ram_GB', 'Weight_kg', 'Memory_GB', 'Has_SSD', 'Has_HDD', \n",
        "                    'Screen_Pixels', 'Is_Touchscreen', 'Is_IPS', 'Is_4K']\n",
        "\n",
        "print(\"\\nüìä NUEVAS FEATURES NUM√âRICAS:\")\n",
        "print(train_processed[nuevas_numericas].describe())\n",
        "\n",
        "# Ver nuevas categ√≥ricas\n",
        "nuevas_categoricas = ['CPU_Brand', 'GPU_Brand']\n",
        "\n",
        "print(\"\\nüìä NUEVAS FEATURES CATEG√ìRICAS:\")\n",
        "for col in nuevas_categoricas:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(train_processed[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CORRECCI√ìN: SCREEN_PIXELS\n",
            "======================================================================\n",
            "‚úÖ Screen_Pixels corregido\n",
            "   Ejemplos: [2073600, 2073600, 2073600, 1296000, 2073600]\n",
            "   Nulos: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"CORRECCI√ìN: SCREEN_PIXELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# El problema es el regex. Vamos a arreglarlo\n",
        "def extract_screen_features_fixed(screen_str):\n",
        "    \"\"\"Extrae caracter√≠sticas de pantalla (CORREGIDO)\"\"\"\n",
        "    if pd.isna(screen_str):\n",
        "        return (np.nan, 0, 0, 0)\n",
        "    \n",
        "    screen_str = str(screen_str)\n",
        "    \n",
        "    # Detectar tipos\n",
        "    is_touchscreen = 1 if 'Touchscreen' in screen_str else 0\n",
        "    is_ips = 1 if 'IPS' in screen_str else 0\n",
        "    is_4k = 1 if '4K' in screen_str or '3840x2160' in screen_str else 0\n",
        "    \n",
        "    # Extraer resoluci√≥n (patr√≥n: 1920x1080)\n",
        "    import re\n",
        "    resolution = re.search(r'(\\d{3,4})\\s*x\\s*(\\d{3,4})', screen_str)\n",
        "    \n",
        "    if resolution:\n",
        "        width = int(resolution.group(1))\n",
        "        height = int(resolution.group(2))\n",
        "        total_pixels = width * height\n",
        "    else:\n",
        "        total_pixels = np.nan\n",
        "    \n",
        "    return (total_pixels, is_touchscreen, is_ips, is_4k)\n",
        "\n",
        "# Reaplicar\n",
        "screen_features = train_processed['ScreenResolution'].apply(extract_screen_features_fixed)\n",
        "train_processed['Screen_Pixels'] = [x[0] for x in screen_features]\n",
        "train_processed['Is_Touchscreen'] = [x[1] for x in screen_features]\n",
        "train_processed['Is_IPS'] = [x[2] for x in screen_features]\n",
        "train_processed['Is_4K'] = [x[3] for x in screen_features]\n",
        "\n",
        "screen_features_test = test_processed['ScreenResolution'].apply(extract_screen_features_fixed)\n",
        "test_processed['Screen_Pixels'] = [x[0] for x in screen_features_test]\n",
        "test_processed['Is_Touchscreen'] = [x[1] for x in screen_features_test]\n",
        "test_processed['Is_IPS'] = [x[2] for x in screen_features_test]\n",
        "test_processed['Is_4K'] = [x[3] for x in screen_features_test]\n",
        "\n",
        "print(\" Screen_Pixels corregido\")\n",
        "print(f\"   Ejemplos: {train_processed['Screen_Pixels'].head(5).tolist()}\")\n",
        "print(f\"   Nulos: {train_processed['Screen_Pixels'].isna().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FEATURE ENGINEERING AVANZADO\n",
            "======================================================================\n",
            "‚úÖ Nuevas features creadas\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# MEJORA: FEATURE ENGINEERING AVANZADO\n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"FEATURE ENGINEERING AVANZADO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Aplicar a train y test\n",
        "for df in [train_processed, test_processed]:\n",
        "    \n",
        "    # 1. PPI (Pixels Per Inch)\n",
        "    df['PPI'] = df['Screen_Pixels'] / (df['Inches'] ** 2)\n",
        "    df['PPI'] = df['PPI'].fillna(df['PPI'].median())\n",
        "    \n",
        "    # 2. RAM por peso\n",
        "    df['RAM_per_Weight'] = df['Ram_GB'] / df['Weight_kg']\n",
        "    df['RAM_per_Weight'] = df['RAM_per_Weight'].fillna(df['RAM_per_Weight'].median())\n",
        "    \n",
        "    # 3. Storage por peso\n",
        "    df['Storage_per_Weight'] = df['Memory_GB'] / df['Weight_kg']\n",
        "    df['Storage_per_Weight'] = df['Storage_per_Weight'].fillna(df['Storage_per_Weight'].median())\n",
        "    \n",
        "    # 4. Total de recursos\n",
        "    df['Total_Resources'] = df['Ram_GB'] + (df['Memory_GB'] / 100)\n",
        "    \n",
        "    # 5. Es gaming\n",
        "    df['Is_Gaming'] = ((df['GPU_Brand'] == 'Nvidia') & (df['Ram_GB'] >= 8)).astype(int)\n",
        "    \n",
        "    # 6. Es premium\n",
        "    df['Is_Premium'] = (\n",
        "        (df['Company'] == 'Apple') | \n",
        "        ((df['Ram_GB'] >= 16) & (df['Has_SSD'] == 1))\n",
        "    ).astype(int)\n",
        "    \n",
        "    # 7. Interacci√≥n RAM x Storage\n",
        "    df['RAM_x_Storage'] = df['Ram_GB'] * np.log1p(df['Memory_GB'])\n",
        "    df['RAM_x_Storage'] = df['RAM_x_Storage'].fillna(df['RAM_x_Storage'].median())\n",
        "\n",
        "print(\" Nuevas features creadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "A√ëADIENDO 'PRODUCT' A LAS FEATURES CATEG√ìRICAS\n",
            "======================================================================\n",
            "\n",
            "üìä AN√ÅLISIS DE 'PRODUCT':\n",
            "   Productos √∫nicos en TRAIN: 480\n",
            "   Productos √∫nicos en TEST: 265\n",
            "\n",
            "   Productos comunes (train ‚à© test): 127\n",
            "   Productos SOLO en train: 353\n",
            "   Productos NUEVOS en test: 138\n",
            "\n",
            "   ‚ö†Ô∏è Hay 138 productos en test no vistos en train\n",
            "      Estos se encodear√°n como -1 (desconocido)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"A√ëADIENDO 'PRODUCT' A LAS FEATURES CATEG√ìRICAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Verificar Product en ambos datasets\n",
        "print(\"\\n AN√ÅLISIS DE 'PRODUCT':\")\n",
        "print(f\"   Productos √∫nicos en TRAIN: {train_processed['Product'].nunique()}\")\n",
        "print(f\"   Productos √∫nicos en TEST: {test_processed['Product'].nunique()}\")\n",
        "\n",
        "# Ver si hay productos nuevos en test\n",
        "products_train = set(train_processed['Product'].unique())\n",
        "products_test = set(test_processed['Product'].unique())\n",
        "\n",
        "productos_nuevos = products_test - products_train\n",
        "productos_comunes = products_test & products_train\n",
        "\n",
        "print(f\"\\n   Productos comunes (train ‚à© test): {len(productos_comunes)}\")\n",
        "print(f\"   Productos SOLO en train: {len(products_train - products_test)}\")\n",
        "print(f\"   Productos NUEVOS en test: {len(productos_nuevos)}\")\n",
        "\n",
        "if len(productos_nuevos) > 0:\n",
        "    print(f\"\\n    Hay {len(productos_nuevos)} productos en test no vistos en train\")\n",
        "    print(f\"      Estos se encodear√°n como -1 (desconocido)\")\n",
        "else:\n",
        "    print(f\"\\n    Todos los productos de test est√°n en train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "PASO 3: PREPARACI√ìN DE DATOS (CON PRODUCT)\n",
            "======================================================================\n",
            "\n",
            "üìä FEATURES SELECCIONADAS:\n",
            "   Num√©ricas: 17\n",
            "   Categ√≥ricas: 6\n",
            "   Total: 23\n",
            "\n",
            "üîß Encoding de features categ√≥ricas...\n",
            "   ‚úÖ Company        :  19 categor√≠as\n",
            "   ‚úÖ Product        : 480 categor√≠as | ‚ö†Ô∏è 146 nuevas en test\n",
            "   ‚úÖ TypeName       :   6 categor√≠as\n",
            "   ‚úÖ OpSys          :   9 categor√≠as\n",
            "   ‚úÖ CPU_Brand      :   5 categor√≠as | ‚ö†Ô∏è 1 nuevas en test\n",
            "   ‚úÖ GPU_Brand      :   3 categor√≠as | ‚ö†Ô∏è 1 nuevas en test\n",
            "\n",
            "üìä Creando datasets finales...\n",
            "\n",
            "‚úÖ DATASETS CREADOS:\n",
            "   X_train: (912, 23)\n",
            "   y_train: (912,)\n",
            "   X_test: (391, 23)\n",
            "\n",
            "üîç VERIFICACI√ìN DE NULOS:\n",
            "   X_train nulos: 12\n",
            "   X_test nulos: 8\n",
            "\n",
            "‚ö†Ô∏è Imputando nulos con mediana...\n",
            "   ‚úÖ Nulos imputados\n",
            "\n",
            "üìã FEATURES FINALES:\n",
            "    1. Inches\n",
            "    2. Ram_GB\n",
            "    3. Weight_kg\n",
            "    4. Memory_GB\n",
            "    5. Has_SSD\n",
            "    6. Has_HDD\n",
            "    7. Screen_Pixels\n",
            "    8. Is_Touchscreen\n",
            "    9. Is_IPS\n",
            "   10. Is_4K\n",
            "   11. PPI\n",
            "   12. RAM_per_Weight\n",
            "   13. Storage_per_Weight\n",
            "   14. Total_Resources\n",
            "   15. Is_Gaming\n",
            "   16. Is_Premium\n",
            "   17. RAM_x_Storage\n",
            "   18. Company_encoded\n",
            "   19. Product_encoded\n",
            "   20. TypeName_encoded\n",
            "   21. OpSys_encoded\n",
            "   22. CPU_Brand_encoded\n",
            "   23. GPU_Brand_encoded\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 3: PREPARACI√ìN DE DATOS (CON PRODUCT)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n",
        "\n",
        "# NUEVO (con features mejoradas)\n",
        "numeric_features = [\n",
        "    'Inches',\n",
        "    'Ram_GB',\n",
        "    'Weight_kg',\n",
        "    'Memory_GB',\n",
        "    'Has_SSD',\n",
        "    'Has_HDD',\n",
        "    'Screen_Pixels',\n",
        "    'Is_Touchscreen',\n",
        "    'Is_IPS',\n",
        "    'Is_4K',\n",
        "    # NUEVAS FEATURES ‚¨á\n",
        "    'PPI',\n",
        "    'RAM_per_Weight',\n",
        "    'Storage_per_Weight',\n",
        "    'Total_Resources',\n",
        "    'Is_Gaming',\n",
        "    'Is_Premium',\n",
        "    'RAM_x_Storage'\n",
        "]\n",
        "\n",
        "# Features categ√≥ricas (AHORA CON PRODUCT)\n",
        "categorical_features = [\n",
        "    'Company',\n",
        "    'Product',      # ‚Üê A√ëADIDO\n",
        "    'TypeName',\n",
        "    'OpSys',\n",
        "    'CPU_Brand',\n",
        "    'GPU_Brand'\n",
        "]\n",
        "\n",
        "print(f\"\\n FEATURES SELECCIONADAS:\")\n",
        "print(f\"   Num√©ricas: {len(numeric_features)}\")\n",
        "print(f\"   Categ√≥ricas: {len(categorical_features)}\")\n",
        "print(f\"   Total: {len(numeric_features) + len(categorical_features)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# LABEL ENCODING DE CATEG√ìRICAS\n",
        "# ============================================================================\n",
        "print(\"\\nüîß Encoding de features categ√≥ricas...\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Diccionario para guardar los encoders\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "    # Fit en train\n",
        "    train_processed[col + '_encoded'] = le.fit_transform(train_processed[col].astype(str))\n",
        "    \n",
        "    # Transform en test (manejo de valores nuevos)\n",
        "    def safe_transform(x, encoder):\n",
        "        try:\n",
        "            return encoder.transform([str(x)])[0]\n",
        "        except:\n",
        "            return -1  # Valor para categor√≠as no vistas\n",
        "    \n",
        "    test_processed[col + '_encoded'] = test_processed[col].apply(\n",
        "        lambda x: safe_transform(x, le)\n",
        "    )\n",
        "    \n",
        "    label_encoders[col] = le\n",
        "    \n",
        "    n_categorias = train_processed[col].nunique()\n",
        "    n_nuevas_test = (test_processed[col + '_encoded'] == -1).sum()\n",
        "    \n",
        "    print(f\"    {col:15s}: {n_categorias:3d} categor√≠as\", end=\"\")\n",
        "    if n_nuevas_test > 0:\n",
        "        print(f\" |  {n_nuevas_test} nuevas en test\")\n",
        "    else:\n",
        "        print(\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# CREAR DATASETS FINALES\n",
        "# ============================================================================\n",
        "print(\"\\n Creando datasets finales...\")\n",
        "\n",
        "# Nombres de features encoded\n",
        "categorical_features_encoded = [col + '_encoded' for col in categorical_features]\n",
        "\n",
        "# Todas las features para el modelo\n",
        "all_features = numeric_features + categorical_features_encoded\n",
        "\n",
        "# X train\n",
        "X_train = train_processed[all_features].copy()\n",
        "y_train = train_processed['Price_in_euros'].copy()\n",
        "\n",
        "# X test\n",
        "X_test = test_processed[all_features].copy()\n",
        " DATASETS CREADOS:\")\n",
        "print(f\"   X_train: {X_train.shape}\")\n",
        "print(f\"   y_train: {y_train.shape}\")\n",
        "print(f\"   X_test: {X_test.shape}\")\n",
        "\n",
        "# Verificar nulos\n",
        "print(f\"\\n VERIFICACI√ìN DE NULOS:\")\n",
        "nulos_train = X_train.isnull().sum().sum()\n",
        "nulos_test = X_test.isnull().sum().sum()\n",
        "\n",
        "print(f\"   X_train nulos: {nulos_train}\")\n",
        "print(f\"   X_test nulos: {nulos_test}\")\n",
        "\n",
        "# Si hay nulos, imputar con mediana\n",
        "if nulos_train > 0 or nulos_test > 0:\n",
        "    print(\"\\n Imputando nulos con mediana...\")\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_train = pd.DataFrame(\n",
        "        imputer.fit_transform(X_train),\n",
        "        columns=X_train.columns,\n",
        "        index=X_train.index\n",
        "    )\n",
        "    X_test = pd.DataFrame(\n",
        "        imputer.transform(X_test),\n",
        "        columns=X_test.columns,\n",
        "        index=X_test.index\n",
        "    )\n",
        "    print(\"    Nulos imputados\")\n",
        "\n",
        "print(\"\\n FEATURES FINALES:\")\n",
        "for i, feat in enumerate(all_features, 1):\n",
        "    print(f\"   {i:2d}. {feat}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "PASO 5.1: BASELINE - COMPARACI√ìN DE MODELOS\n",
            "======================================================================\n",
            "\n",
            " ¬øQU√â ES UN BASELINE?\n",
            "\n",
            "Un baseline es un modelo SIMPLE que sirve de referencia:\n",
            "  ‚Ä¢ Si tu modelo complejo NO supera al baseline ‚Üí Problema\n",
            "  ‚Ä¢ Si tu modelo complejo S√ç supera al baseline ‚Üí Vas bien\n",
            "\n",
            "Probamos:\n",
            "  1. Linear Regression (m√°s simple posible)\n",
            "  2. Random Forest (robusto, medio complejo)\n",
            "  3. LightGBM (complejo, mejor rendimiento esperado)\n",
            "\n",
            "\\n1Ô∏è‚É£ BASELINE 1: Linear Regression\n",
            "----------------------------------------------------------------------\n",
            "    Entrenando con Cross-Validation (5-fold)...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     35\u001b[39m lr = LinearRegression()\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m    Entrenando con Cross-Validation (5-fold)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m lr_scores = cross_val_score(\n\u001b[32m     39\u001b[39m     lr, \n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[43mX_train\u001b[49m, \n\u001b[32m     41\u001b[39m     y_train, \n\u001b[32m     42\u001b[39m     cv=kf, \n\u001b[32m     43\u001b[39m     scoring=\u001b[33m'\u001b[39m\u001b[33mneg_root_mean_squared_error\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     44\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m lr_rmse = -lr_scores.mean()\n\u001b[32m     48\u001b[39m lr_std = lr_scores.std()\n",
            "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PASO 5.1: BASELINE DE MODELOS\n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"PASO 5.1: BASELINE - COMPARACI√ìN DE MODELOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        " ¬øQU√â ES UN BASELINE?\n",
        "\n",
        "Un baseline es un modelo SIMPLE que sirve de referencia:\n",
        "  ‚Ä¢ Si tu modelo complejo NO supera al baseline ‚Üí Problema\n",
        "  ‚Ä¢ Si tu modelo complejo S√ç supera al baseline ‚Üí Vas bien\n",
        "  \n",
        "Probamos:\n",
        "  1. Linear Regression (m√°s simple posible)\n",
        "  2. Random Forest (robusto, medio complejo)\n",
        "  3. LightGBM (complejo, mejor rendimiento esperado)\n",
        "\"\"\")\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import numpy as np\n",
        "\n",
        "# Configurar Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ============================================================================\n",
        "# BASELINE 1: LINEAR REGRESSION\n",
        "# ============================================================================\n",
        "print(\"\\\\n1Ô∏è‚É£ BASELINE 1: Linear Regression\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "print(\"    Entrenando con Cross-Validation (5-fold)...\")\n",
        "lr_scores = cross_val_score(\n",
        "    lr, \n",
        "    X_train, \n",
        "    y_train, \n",
        "    cv=kf, \n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_rmse = -lr_scores.mean()\n",
        "lr_std = lr_scores.std()\n",
        "\n",
        "print(f\"    Completado\")\n",
        "print(f\"\\\\n    RESULTADOS:\")\n",
        "print(f\"      RMSE: {lr_rmse:.2f} ¬± {lr_std:.2f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# BASELINE 2: RANDOM FOREST\n",
        "# ============================================================================\n",
        "print(\"\\\\n2Ô∏è‚É£ BASELINE 2: Random Forest\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"    Entrenando con Cross-Validation (5-fold)...\")\n",
        "print(\"   (Esto puede tardar 30-60 segundos...)\")\n",
        "\n",
        "rf_scores = cross_val_score(\n",
        "    rf, \n",
        "    X_train, \n",
        "    y_train, \n",
        "    cv=kf,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_rmse = -rf_scores.mean()\n",
        "rf_std = rf_scores.std()\n",
        "\n",
        "print(f\"    Completado\")\n",
        "print(f\"\\\\n    RESULTADOS:\")\n",
        "print(f\"      RMSE: {rf_rmse:.2f} ¬± {rf_std:.2f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# COMPARACI√ìN DE BASELINES\n",
        "# ============================================================================\n",
        "print(\"\\\\n\" + \"=\"*70)\n",
        "print(\" COMPARACI√ìN DE BASELINES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "PASO 4: ENTRENAMIENTO DE LIGHTGBM\n",
            "======================================================================\n",
            "\n",
            "ü§ñ Configurando LightGBM...\n",
            "‚úÖ Modelo configurado\n",
            "\n",
            "üìä Realizando Cross-Validation (5-fold)...\n",
            "   (Esto puede tardar 1-2 minutos...)\n",
            "\n",
            "üìä RESULTADOS DE CROSS-VALIDATION:\n",
            "   RMSE por fold:\n",
            "      Fold 1: 303.88\n",
            "      Fold 2: 271.23\n",
            "      Fold 3: 271.75\n",
            "      Fold 4: 257.40\n",
            "      Fold 5: 324.62\n",
            "\n",
            "   ==================================================\n",
            "   üéØ RMSE MEDIO: 285.78 ¬± 24.70\n",
            "   ==================================================\n",
            "\n",
            "   ‚úÖ ¬°OBJETIVO ALCANZADO! (RMSE < 400)\n",
            "\n",
            "üöÄ Entrenando modelo final con todos los datos...\n",
            "‚úÖ Modelo entrenado\n",
            "\n",
            "üìä RMSE EN TRAIN: 75.54\n",
            "   (Referencia - El RMSE real es el de CV: 285.78)\n",
            "\n",
            "üìä TOP 15 FEATURES M√ÅS IMPORTANTES:\n",
            "           feature  importance\n",
            "   Product_encoded        5732\n",
            "    RAM_per_Weight        4686\n",
            "         Weight_kg        4560\n",
            "Storage_per_Weight        4274\n",
            "   Company_encoded        1599\n",
            "   Total_Resources        1445\n",
            "               PPI        1441\n",
            " CPU_Brand_encoded        1022\n",
            "            Inches         959\n",
            "     RAM_x_Storage         956\n",
            "     Screen_Pixels         938\n",
            "  TypeName_encoded         733\n",
            "     OpSys_encoded         680\n",
            "         Memory_GB         656\n",
            "            Is_IPS         542\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 4: ENTRENAMIENTO DE LIGHTGBM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURACI√ìN DEL MODELO\n",
        "# ============================================================================\n",
        "print(\"\\n Configurando LightGBM...\")\n",
        "\n",
        "# NUEVO (tunning mejorado)\n",
        "model = lgb.LGBMRegressor(\n",
        "    n_estimators=2000,      # ‚¨Ü M√°s √°rboles\n",
        "    learning_rate=0.03,     # ‚¨á Learning rate m√°s bajo\n",
        "    max_depth=8,            # ‚¨Ü √Årboles m√°s profundos\n",
        "    num_leaves=40,          # ‚¨Ü M√°s hojas\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_samples=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "print(\" Modelo configurado\")\n",
        "\n",
        "# ============================================================================\n",
        "# CROSS-VALIDATION\n",
        "# ============================================================================\n",
        "print(\"\\n Realizando Cross-Validation (5-fold)...\")\n",
        "print(\"   (Esto puede tardar 1-2 minutos...)\")\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    model, \n",
        "    X_train, \n",
        "    y_train, \n",
        "    cv=kf, \n",
        "    scoring='neg_root_mean_squared_error',  # RMSE\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Convertir a positivo\n",
        "cv_rmse = -cv_scores\n",
        "\n",
        "print(f\"\\n RESULTADOS DE CROSS-VALIDATION:\")\n",
        "print(f\"   RMSE por fold:\")\n",
        "for i, score in enumerate(cv_rmse, 1):\n",
        "    print(f\"      Fold {i}: {score:.2f}\")\n",
        "\n",
        "print(f\"\\n   {'='*50}\")\n",
        "print(f\"    RMSE MEDIO: {cv_rmse.mean():.2f} ¬± {cv_rmse.std():.2f}\")\n",
        "print(f\"   {'='*50}\")\n",
        "\n",
        "if cv_rmse.mean() < 400:\n",
        "    print(f\"\\n   ¬°OBJETIVO ALCANZADO! (RMSE < 400)\")\n",
        "elif cv_rmse.mean() < 450:\n",
        "    print(f\"\\n    Cerca del objetivo (tunear hiperpar√°metros)\")\n",
        "else:\n",
        "    print(f\"\\n    Lejos del objetivo (revisar features)\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENTRENAR CON TODOS LOS DATOS\n",
        "# ============================================================================\n",
        "print(\"\\n Entrenando modelo final con todos los datos...\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\" Modelo entrenado\")\n",
        "\n",
        "# RMSE en train (para referencia)\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "print(f\"\\n RMSE EN TRAIN: {train_rmse:.2f}\")\n",
        "print(f\"   (Referencia - El RMSE real es el de CV: {cv_rmse.mean():.2f})\")\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTANCIA DE FEATURES\n",
        "# ============================================================================\n",
        "print(\"\\n TOP 15 FEATURES M√ÅS IMPORTANTES:\")\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': all_features,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(feature_importance.head(15).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "PASO 5: PREDICCIONES Y SUBMISSION\n",
            "======================================================================\n",
            "\n",
            "üîÆ Generando predicciones para test...\n",
            "‚úÖ Predicciones generadas: 391\n",
            "\n",
            "üìä ESTAD√çSTICAS DE PREDICCIONES:\n",
            "   Precio m√≠nimo predicho: 221.22 ‚Ç¨\n",
            "   Precio m√°ximo predicho: 5535.99 ‚Ç¨\n",
            "   Precio medio predicho: 1126.42 ‚Ç¨\n",
            "   Precio mediano predicho: 965.59 ‚Ç¨\n",
            "\n",
            "üíæ ARCHIVO GUARDADO: submission.csv\n",
            "\n",
            "üìã Primeras 10 predicciones:\n",
            " laptop_ID  Price_in_euros\n",
            "       209     1143.228502\n",
            "      1281      289.335853\n",
            "      1168      344.374493\n",
            "      1231      820.365899\n",
            "      1020     1054.912451\n",
            "       379      528.876922\n",
            "       553      692.498873\n",
            "       172     1094.424555\n",
            "       779     1067.763729\n",
            "       609      322.520844\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚úÖ PROCESO COMPLETADO\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "üìä RESUMEN FINAL:\n",
            "   ‚Ä¢ Features usadas: 23 (10 num√©ricas + 6 categ√≥ricas)\n",
            "   ‚Ä¢ Incluye: Product (480 categor√≠as)\n",
            "   ‚Ä¢ RMSE esperado (CV): 285.78 ¬± 24.70\n",
            "   ‚Ä¢ Objetivo Kaggle: < 400\n",
            "   ‚Ä¢ Estado: ‚úÖ ALCANZADO\n",
            "\n",
            "üìÅ ARCHIVOS GENERADOS:\n",
            "   ‚Ä¢ submission.csv (391 predicciones)\n",
            "\n",
            "üéØ PR√ìXIMOS PASOS:\n",
            "   1. Sube submission.csv a Kaggle\n",
            "   2. Compara RMSE del leaderboard con CV (285.78)\n",
            "   3. Si coinciden ‚Üí Todo correcto ‚úÖ\n",
            "   4. Si RMSE Kaggle > CV ‚Üí Posible overfitting\n",
            "   5. Si RMSE Kaggle < CV ‚Üí ¬°Mejor de lo esperado! üéâ\n",
            "\n",
            "üí° SI RMSE > 400:\n",
            "   ‚Ä¢ Tunear hiperpar√°metros (aumentar n_estimators, bajar learning_rate)\n",
            "   ‚Ä¢ Crear features de interacci√≥n (PPI, Gaming, etc.)\n",
            "   ‚Ä¢ Probar ensemble de modelos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 5: PREDICCIONES Y SUBMISSION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Predecir en test\n",
        "print(\"\\n Generando predicciones para test...\")\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(f\" Predicciones generadas: {len(predictions)}\")\n",
        "print(f\"\\n ESTAD√çSTICAS DE PREDICCIONES:\")\n",
        "print(f\"   Pecio m√≠nimo predicho: {predictions.min():.2f} ‚Ç¨\")\n",
        "print(f\"   Precio m√°ximo predicho: {predictions.max():.2f} ‚Ç¨\")\n",
        "print(f\"   Precio medio predicho: {predictions.mean():.2f} ‚Ç¨\")\n",
        "print(f\"   Precio mediano predicho: {np.median(predictions):.2f} ‚Ç¨\")\n",
        "\n",
        "# Crear submission\n",
        "submission = pd.DataFrame({\n",
        "    'laptop_ID': test_processed['laptop_ID'],\n",
        "    'Price_in_euros': predictions\n",
        "})\n",
        "\n",
        "# Guardar\n",
        "submission.to_csv('submission_improved.csv', index=False)\n",
        "\n",
        "print(f\"\\n ARCHIVO GUARDADO: submission.csv\")\n",
        "print(f\"\\n Primeras 10 predicciones:\")\n",
        "print(submission.head(10).to_string(index=False))\n",
        "\n",
        "print(f\"\"\"\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        " PROCESO COMPLETADO\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        " RESUMEN FINAL:\n",
        "   ‚Ä¢ Features usadas: {len(all_features)} (10 num√©ricas + 6 categ√≥ricas)\n",
        "   ‚Ä¢ Incluye: Product (480 categor√≠as)\n",
        "   ‚Ä¢ RMSE esperado (CV): {cv_rmse.mean():.2f} ¬± {cv_rmse.std():.2f}\n",
        "   ‚Ä¢ Objetivo Kaggle: < 400\n",
        "   ‚Ä¢ Estado: {' ALCANZADO' if cv_rmse.mean() < 400 else '‚ö†Ô∏è REVISAR'}\n",
        "\n",
        " ARCHIVOS GENERADOS:\n",
        "   ‚Ä¢ submission.csv ({len(submission)} predicciones)\n",
        "\n",
        " PR√ìXIMOS PASOS:\n",
        "   1. Sube submission.csv a Kaggle\n",
        "   2. Compara RMSE del leaderboard con CV ({cv_rmse.mean():.2f})\n",
        "   3. Si coinciden ‚Üí Todo correcto \n",
        "   4. Si RMSE Kaggle > CV ‚Üí Posible overfitting\n",
        "   5. Si RMSE Kaggle < CV ‚Üí ¬°Mejor de lo esperado! üéâ\n",
        "\n",
        " SI RMSE > 400:\n",
        "   ‚Ä¢ Tunear hiperpar√°metros (aumentar n_estimators, bajar learning_rate)\n",
        "   ‚Ä¢ Crear features de interacci√≥n (PPI, Gaming, etc.)\n",
        "   ‚Ä¢ Probar ensemble de modelos\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ VERIFICACI√ìN FINAL DE SUBMISSION.CSV:\n",
            "======================================================================\n",
            "\n",
            "üìã FORMATO DEL ARCHIVO:\n",
            "   Columnas: ['laptop_ID', 'Price_in_euros']\n",
            "   Filas: 391\n",
            "   Columna 1 (ID): laptop_ID\n",
            "   Columna 2 (Precio): Price_in_euros\n",
            "\n",
            "üìä PRIMERAS 5 FILAS:\n",
            "   laptop_ID  Price_in_euros\n",
            "0        209     1194.910244\n",
            "1       1281      308.557594\n",
            "2       1168      308.225638\n",
            "3       1231      905.020887\n",
            "4       1020     1050.592808\n",
            "\n",
            "üìä √öLTIMAS 5 FILAS:\n",
            "     laptop_ID  Price_in_euros\n",
            "386        820     2276.204500\n",
            "387        948      829.150096\n",
            "388        483     1288.557235\n",
            "389       1017      937.300641\n",
            "390        421     1192.239609\n",
            "\n",
            "üîç Valores nulos en submission: 0\n",
            "   ‚úÖ No hay nulos - Archivo listo para subir\n",
            "\n",
            "üîç IDs √∫nicos: 391\n",
            "   ‚úÖ Todos los IDs son √∫nicos\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "üéâ ¬°TODO LISTO PARA SUBIR A KAGGLE!\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "ARCHIVO: submission.csv ‚úÖ\n",
            "RMSE ESPERADO: ~275.67 (muy por debajo de 400) ‚úÖ\n",
            "FORMATO CORRECTO: S√≠ ‚úÖ\n",
            "\n",
            "üéØ SUBE EL ARCHIVO Y COMPARTE TU RESULTADO!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n VERIFICACI√ìN FINAL DE SUBMISSION.CSV:\")\n",
        "\n",
        "\n",
        "# Leer el archivo generado\n",
        "submission_check = pd.read_csv('submission.csv')\n",
        "\n",
        "print(f\"\\n FORMATO DEL ARCHIVO:\")\n",
        "print(f\"   Columnas: {submission_check.columns.tolist()}\")\n",
        "print(f\"   Filas: {len(submission_check)}\")\n",
        "print(f\"   Columna 1 (ID): {submission_check.columns[0]}\")\n",
        "print(f\"   Columna 2 (Precio): {submission_check.columns[1]}\")\n",
        "\n",
        "print(f\"\\n PRIMERAS 5 FILAS:\")\n",
        "print(submission_check.head())\n",
        "\n",
        "print(f\"\\n √öLTIMAS 5 FILAS:\")\n",
        "print(submission_check.tail())\n",
        "\n",
        "# Verificar que no hay nulos\n",
        "nulos_submission = submission_check.isnull().sum().sum()\n",
        "print(f\"\\n Valores nulos en submission: {nulos_submission}\")\n",
        "\n",
        "if nulos_submission == 0:\n",
        "    print(\"    No hay nulos - Archivo listo para subir\")\n",
        "else:\n",
        "    print(\"    HAY NULOS - REVISAR\")\n",
        "\n",
        "# Verificar IDs\n",
        "ids_unicos = submission_check['laptop_ID'].nunique()\n",
        "print(f\"\\nüîç IDs √∫nicos: {ids_unicos}\")\n",
        "\n",
        "if ids_unicos == len(submission_check):\n",
        "    print(\"    Todos los IDs son √∫nicos\")\n",
        "else:\n",
        "    print(\"    Hay IDs duplicados\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "PASO 6: VERIFICAR Y GUARDAR SUBMISSION\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:72: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:72: SyntaxWarning: invalid escape sequence '\\ '\n",
            "C:\\Users\\lupep\\AppData\\Local\\Temp\\ipykernel_14124\\3435053973.py:72: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  print(f\"\\ ARCHIVO GUARDADO: submission.csv\")\n",
            "C:\\Users\\lupep\\AppData\\Local\\Temp\\ipykernel_14124\\3435053973.py:72: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  print(f\"\\ ARCHIVO GUARDADO: submission.csv\")\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Cargar sample_submission con la ruta correcta\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m sample_submission = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/sample_submission.csv\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# ‚Üê RUTA CORRECTA\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m VERIFICANDO SUBMISSION...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Check 1: Shape\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PASO 6: VERIFICAR Y GUARDAR SUBMISSION\n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"PASO 6: VERIFICAR Y GUARDAR SUBMISSION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Cargar sample_submission con la ruta correcta\n",
        "sample_submission = pd.read_csv('data/sample_submission.csv')  # ‚Üê RUTA CORRECTA\n",
        "\n",
        "print(\"\\n VERIFICANDO SUBMISSION...\")\n",
        "\n",
        "# Check 1: Shape\n",
        "print(f\"\\n1Ô∏è Shape:\")\n",
        "print(f\"   Tu submission: {submission.shape}\")\n",
        "print(f\"   Esperado: {sample_submission.shape}\")\n",
        "if submission.shape == sample_submission.shape:\n",
        "    print(f\"    Correcto\")\n",
        "else:\n",
        "    print(f\"    Incorrecto\")\n",
        "\n",
        "# Check 2: Columnas\n",
        "print(f\"\\n2Ô∏è‚É£ Columnas:\")\n",
        "print(f\"   Tus columnas: {submission.columns.tolist()}\")\n",
        "print(f\"   Esperadas: {sample_submission.columns.tolist()}\")\n",
        "if submission.columns.tolist() == sample_submission.columns.tolist():\n",
        "    print(f\"    Correcto\")\n",
        "else:\n",
        "    print(f\"    Incorrecto\")\n",
        "\n",
        "# Check 3: IDs\n",
        "print(f\"\\n3Ô∏è‚É£ IDs:\")\n",
        "if submission['laptop_ID'].tolist() == sample_submission['laptop_ID'].tolist():\n",
        "    print(f\"    IDs correctos ({len(submission)} laptops)\")\n",
        "else:\n",
        "    print(f\"    IDs no coinciden\")\n",
        "\n",
        "# Check 4: Nulos\n",
        "print(f\"\\n4Ô∏è‚É£ Valores nulos:\")\n",
        "nulos = submission.isnull().sum().sum()\n",
        "print(f\"   Nulos encontrados: {nulos}\")\n",
        "if nulos == 0:\n",
        "    print(f\"    Sin valores nulos\")\n",
        "else:\n",
        "    print(f\"    Hay nulos - CORREGIR\")\n",
        "\n",
        "# Check 5: Tipos\n",
        "print(f\"\\n5Ô∏è‚É£ Tipos de datos:\")\n",
        "print(f\"   Price_in_euros: {submission['Price_in_euros'].dtype}\")\n",
        "if submission['Price_in_euros'].dtype in ['float64', 'float32']:\n",
        "    print(f\"    Tipo correcto\")\n",
        "else:\n",
        "    print(f\"    Debe ser float\")\n",
        "\n",
        "# Si todo OK, guardar\n",
        "all_ok = (\n",
        "    submission.shape == sample_submission.shape and\n",
        "    submission.columns.tolist() == sample_submission.columns.tolist() and\n",
        "    submission['laptop_ID'].tolist() == sample_submission['laptop_ID'].tolist() and\n",
        "    nulos == 0 and\n",
        "    submission['Price_in_euros'].dtype in ['float64', 'float32']\n",
        ")\n",
        "\n",
        "if all_ok:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" ¬°TODAS LAS VERIFICACIONES PASADAS!\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Guardar\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "    \n",
        "    print(f\"\\ ARCHIVO GUARDADO: submission.csv\")\n",
        "    print(f\"\\n RESUMEN:\")\n",
        "    print(f\"   ‚Ä¢ Filas: {len(submission)}\")\n",
        "    print(f\"   ‚Ä¢ Columnas: {list(submission.columns)}\")\n",
        "    print(f\"   ‚Ä¢ RMSE esperado (CV): ~275\")\n",
        "    \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Cargando archivos desde carpeta 'data'...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# RE-CARGAR con rutas expl√≠citas\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Cargando archivos desde carpeta \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/train.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/test.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m sample_submission = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/sample_submission.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# RE-CARGAR con rutas expl√≠citas\n",
        "print(\"\\n Cargando archivos desde carpeta 'data'...\")\n",
        "\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
        "\n",
        "print(f\"\\n Archivos cargados\")\n",
        "\n",
        "print(f\"\\n VERIFICACI√ìN:\")\n",
        "print(f\"   train.csv: {train.shape} | Tiene precio: {'Price_in_euros' in train.columns}\")\n",
        "print(f\"   test.csv: {test.shape} | Tiene precio: {'Price_in_euros' in test.columns}\")\n",
        "print(f\"   sample_submission.csv: {sample_submission.shape}\")\n",
        "\n",
        "# Ver primeros IDs\n",
        "print(f\"\\n PRIMEROS 3 IDs:\")\n",
        "print(f\"   train: {train['laptop_ID'].head(3).tolist()}\")\n",
        "print(f\"   test: {test['laptop_ID'].head(3).tolist()}\")\n",
        "print(f\"   sample: {sample_submission['laptop_ID'].head(3).tolist()}\")\n",
        "\n",
        "# Verificar que test y sample tengan los mismos IDs\n",
        "if test['laptop_ID'].tolist() == sample_submission['laptop_ID'].tolist():\n",
        "    print(f\"\\n    test.csv y sample_submission.csv tienen los MISMOS IDs\")\n",
        "else:\n",
        "    print(f\"\\n    test.csv y sample_submission.csv tienen IDs DIFERENTES\")\n",
        "    print(f\"\\n    PROBLEMA: Los archivos no coinciden\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# ENSEMBLE COMPLETO - VERSI√ìN INDEPENDIENTE\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   X_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mX_train\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   y_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   X_test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ENSEMBLE COMPLETO - VERSI√ìN INDEPENDIENTE\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "print(f\"   X_train: {X_train.shape}\")\n",
        "print(f\"   y_train: {y_train.shape}\")\n",
        "print(f\"   X_test: {X_test.shape}\")\n",
        "\n",
        "# Instalar XGBoost si no est√° (ejecutar solo si da error)\n",
        "# !pip install xgboost\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Modelos base\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=8,\n",
        "    num_leaves=40,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_samples=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "meta_model = Ridge(alpha=1.0)\n",
        "\n",
        "ensemble = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('lightgbm', lgb_model),\n",
        "        ('xgboost', xgb_model),\n",
        "        ('random_forest', rf_model)\n",
        "    ],\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\" Modelos configurados\")\n",
        "\n",
        "# Cross-Validation (opcional, comentar si tarda mucho)\n",
        "print(\"\\n Evaluando con CV (3-fold)...\")\n",
        "print(\"    Esperando 3-5 minutos...\")\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "try:\n",
        "    cv_scores = cross_val_score(\n",
        "        ensemble, X_train, y_train,\n",
        "        cv=kf,\n",
        "        scoring='neg_root_mean_squared_error'\n",
        "    )\n",
        "    print(f\"\\n CV completado\")\n",
        "    print(f\"   RMSE (CV): {-cv_scores.mean():.2f} ¬± {cv_scores.std():.2f}\")\n",
        "except:\n",
        "    print(\"    CV omitido (para ir m√°s r√°pido)\")\n",
        "\n",
        "# Entrenar\n",
        "print(\"\\n Entrenando ensemble final...\")\n",
        "ensemble.fit(X_train, y_train)\n",
        "print(\" Entrenado\")\n",
        "\n",
        "# Predecir\n",
        "print(\"\\n Prediciendo...\")\n",
        "predictions_ensemble = ensemble.predict(X_test)\n",
        "\n",
        "# Submission\n",
        "submission_ensemble = pd.DataFrame({\n",
        "    'laptop_ID': test_processed['laptop_ID'],\n",
        "    'Price_in_euros': predictions_ensemble\n",
        "})\n",
        "\n",
        "submission_ensemble.to_csv('submission_ensemble.csv', index=False)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\" ¬°COMPLETADO!\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\n Archivo: submission_ensemble.csv\")\n",
        "print(f\" Predicciones: {len(submission_ensemble)}\")\n",
        "print(f\" LISTO PARA SUBIR A KAGGLE\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6x5RxgS1Dv6"
      },
      "source": [
        "### 2.3 Definir X e y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oviz1YAs1Dv6"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Price_in_euros'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPrice_in_euros\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mPrice_in_euros\u001b[39m\u001b[33m'\u001b[39m].copy()\n\u001b[32m      3\u001b[39m X.shape\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
            "\u001b[31mKeyError\u001b[39m: \"['Price_in_euros'] not found in axis\""
          ]
        }
      ],
      "source": [
        "X = df.drop(['Price_in_euros'], axis=1)\n",
        "y = df['Price_in_euros'].copy()\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpPyLXwy1Dv6"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YhM9bjU1Dv6"
      },
      "source": [
        "### 2.4 Dividir X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydmaYf4M1Dv6"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf7-NP0O1Dv6"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ly7JZ6J1Dv6"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQlw8Vdr1Dv6"
      },
      "source": [
        "## 3. Procesado de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPgDX-iM1Dv6"
      },
      "source": [
        "Nuestro target es la columna `Price_in_euros`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjzNxMU91Dv6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zATD1vpn1Dv6"
      },
      "source": [
        "-----------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojsM78OY1Dv6"
      },
      "source": [
        "## 4. Modelado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65rieXt81Dv6"
      },
      "source": [
        "### 4.1 Baseline de modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fOmhsmB1Dv6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br9_gKrL1Dv6"
      },
      "source": [
        "### 4.2 Sacar m√©tricas, valorar los modelos\n",
        "\n",
        "Recuerda que en la competici√≥n se va a evaluar con la m√©trica de ``RMSE``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSN5UZAE1Dv7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imOqya6z1Dv7"
      },
      "source": [
        "### 4.3 Optimizaci√≥n (up to you ü´∞üèª)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx5MCFni1Dv7"
      },
      "source": [
        "-----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV7xlHP01Dv7"
      },
      "source": [
        "## Una vez listo el modelo, toca predecir ``test.csv``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWUBEtcP1Dv7"
      },
      "source": [
        "**RECUERDA: APLICAR LAS TRANSFORMACIONES QUE HAYAS REALIZADO EN `train.csv` a `test.csv`.**\n",
        "\n",
        "\n",
        "V√©ase:\n",
        "- Estandarizaci√≥n/Normalizaci√≥n\n",
        "- Eliminaci√≥n de Outliers\n",
        "- Eliminaci√≥n de columnas\n",
        "- Creaci√≥n de columnas nuevas\n",
        "- Gesti√≥n de valores nulos\n",
        "- Y un largo etc√©tera de t√©cnicas que como Data Scientist hayas considerado las mejores para tu dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uOZ30nP1Dv7"
      },
      "source": [
        "## 1. Carga los datos de `test.csv` para predecir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbTMLc3w1Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred = pd.read_csv(\"./data/test.csv\")\n",
        "X_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66MczL1e1Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6eGCkhQ1Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WA_TDy81Dv7"
      },
      "source": [
        " ## 2. Replicar el procesado para ``test.csv``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmTeHhx61Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0gMgEX71Dv7"
      },
      "outputs": [],
      "source": [
        "predictions_submit = model.predict(X_pred)\n",
        "predictions_submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm1E4KZC1Dv8"
      },
      "source": [
        "**¬°OJO! ¬øPor qu√© me da error?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51qH2nmY1Dv8"
      },
      "source": [
        "IMPORTANTE:\n",
        "\n",
        "- SI EL ARRAY CON EL QUE HICISTEIS `.fit()` ERA DE 4 COLUMNAS, PARA `.predict()` DEBEN SER LAS MISMAS\n",
        "- SI AL ARRAY CON EL QUE HICISTEIS `.fit()` LO NORMALIZASTEIS, PARA `.predict()` DEB√âIS NORMALIZARLO\n",
        "- TODO IGUAL SALVO **BORRAR FILAS**, EL N√öMERO DE ROWS SE DEBE MANTENER EN ESTE SET, PUES LA PREDICCI√ìN DEBE TENER **391 FILAS**, SI O SI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEJRE2TD1Dv8"
      },
      "source": [
        "**Entonces, si al cargar los datos de ``train.csv`` usaste `index_col=0`, ¬øtendr√© que hacer lo tambi√©n para el `test.csv`?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc6QsmVs1Dv8"
      },
      "outputs": [],
      "source": [
        "# ¬øQu√© opin√°is?\n",
        "# ¬øS√≠, no?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLUSmwh1Dv8"
      },
      "source": [
        "![wow.jpeg](attachment:wow.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv_-fwkS1Dv8"
      },
      "source": [
        "## 3. **¬øQu√© es lo que subir√°s a Kaggle?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfsoAjbO1Dv8"
      },
      "source": [
        "**Para subir a Kaggle la predicci√≥n esta tendr√° que tener una forma espec√≠fica.**\n",
        "\n",
        "En este caso, la **MISMA** forma que `sample_submission.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdsWqPu11Dv8"
      },
      "outputs": [],
      "source": [
        "sample = pd.read_csv(\"data/sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7zJiUYJ1Dv8"
      },
      "outputs": [],
      "source": [
        "sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSQgkXv_1Dv8"
      },
      "outputs": [],
      "source": [
        "sample.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ZUO8pF1Dv8"
      },
      "source": [
        "## 4. Mete tus predicciones en un dataframe llamado ``submission``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKVRMDUY1Dv8"
      },
      "outputs": [],
      "source": [
        "#¬øC√≥mo creamos la submission?\n",
        "submission = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn2nLy6c1Dv8"
      },
      "outputs": [],
      "source": [
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY1MluFr1Dv9"
      },
      "outputs": [],
      "source": [
        "submission.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qMGcOJq1Dv9"
      },
      "source": [
        "## 5. P√°sale el CHEQUEADOR para comprobar que efectivamente est√° listo para subir a Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFxk4hYQ1Dv9"
      },
      "outputs": [],
      "source": [
        "def chequeador(df_to_submit):\n",
        "    \"\"\"\n",
        "    Esta funci√≥n se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
        "\n",
        "    Si es as√≠, se guardar√° el dataframe en un `csv` y estar√° listo para subir a Kaggle.\n",
        "\n",
        "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
        "\n",
        "    Si a√∫n no:\n",
        "    - apaga tu ordenador,\n",
        "    - date una vuelta,\n",
        "    - enciendelo otra vez,\n",
        "    - abre este notebook y\n",
        "    - leelo todo de nuevo.\n",
        "    Todos nos merecemos una segunda oportunidad. Tambi√©n t√∫.\n",
        "    \"\"\"\n",
        "    if df_to_submit.shape == sample.shape:\n",
        "        if df_to_submit.columns.all() == sample.columns.all():\n",
        "            if df_to_submit.laptop_ID.all() == sample.laptop_ID.all():\n",
        "                print(\"You're ready to submit!\")\n",
        "                df_to_submit.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
        "                urllib.request.urlretrieve(\"https://www.mihaileric.com/static/evaluation-meme-e0a350f278a36346e6d46b139b1d0da0-ed51e.jpg\", \"gfg.png\")\n",
        "                img = Image.open(\"gfg.png\")\n",
        "                img.show()\n",
        "            else:\n",
        "                print(\"Check the ids and try again\")\n",
        "        else:\n",
        "            print(\"Check the names of the columns and try again\")\n",
        "    else:\n",
        "        print(\"Check the number of rows and/or columns and try again\")\n",
        "        print(\"\\nMensaje secreto del TA: No me puedo creer que despu√©s de todo este notebook hayas hecho alg√∫n cambio en las filas de `test.csv`. Lloro.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnZqqe131Dv9"
      },
      "outputs": [],
      "source": [
        "chequeador(submission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 1: CARGAR DATOS\n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"PASO 1: CARGA DE DATOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
        "\n",
        "print(f\"\\n Datos cargados:\")\n",
        "print(f\"   train: {train.shape}\")\n",
        "print(f\"   test: {test.shape}\")\n",
        "print(f\"   sample: {sample_submission.shape}\")\n",
        "\n",
        "train_processed = train.copy()\n",
        "test_processed = test.copy()\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 2: FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 2: FEATURE ENGINEERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import re\n",
        "\n",
        "# 1. RAM\n",
        "def extract_ram(ram_str):\n",
        "    if pd.isna(ram_str):\n",
        "        return np.nan\n",
        "    numbers = re.findall(r'\\d+', str(ram_str))\n",
        "    return int(numbers[0]) if numbers else np.nan\n",
        "\n",
        "train_processed['Ram_GB'] = train_processed['Ram'].apply(extract_ram)\n",
        "test_processed['Ram_GB'] = test_processed['Ram'].apply(extract_ram)\n",
        "\n",
        "# 2. WEIGHT\n",
        "def extract_weight(weight_str):\n",
        "    if pd.isna(weight_str):\n",
        "        return np.nan\n",
        "    numbers = re.findall(r'\\d+\\.?\\d*', str(weight_str))\n",
        "    return float(numbers[0]) if numbers else np.nan\n",
        "\n",
        "train_processed['Weight_kg'] = train_processed['Weight'].apply(extract_weight)\n",
        "test_processed['Weight_kg'] = test_processed['Weight'].apply(extract_weight)\n",
        "\n",
        "# 3. MEMORY\n",
        "def extract_memory_features(memory_str):\n",
        "    if pd.isna(memory_str):\n",
        "        return (np.nan, 0, 0)\n",
        "    memory_str = str(memory_str).upper()\n",
        "    has_ssd = 1 if 'SSD' in memory_str else 0\n",
        "    has_hdd = 1 if 'HDD' in memory_str else 0\n",
        "    total_gb = 0\n",
        "    gb_matches = re.findall(r'(\\d+)\\s*GB', memory_str)\n",
        "    tb_matches = re.findall(r'(\\d+)\\s*TB', memory_str)\n",
        "    for gb in gb_matches:\n",
        "        total_gb += int(gb)\n",
        "    for tb in tb_matches:\n",
        "        total_gb += int(tb) * 1024\n",
        "    return (total_gb if total_gb > 0 else np.nan, has_ssd, has_hdd)\n",
        "\n",
        "memory_train = train_processed['Memory'].apply(extract_memory_features)\n",
        "train_processed['Memory_GB'] = [x[0] for x in memory_train]\n",
        "train_processed['Has_SSD'] = [x[1] for x in memory_train]\n",
        "train_processed['Has_HDD'] = [x[2] for x in memory_train]\n",
        "\n",
        "memory_test = test_processed['Memory'].apply(extract_memory_features)\n",
        "test_processed['Memory_GB'] = [x[0] for x in memory_test]\n",
        "test_processed['Has_SSD'] = [x[1] for x in memory_test]\n",
        "test_processed['Has_HDD'] = [x[2] for x in memory_test]\n",
        "\n",
        "# 4. SCREEN\n",
        "def extract_screen_features(screen_str):\n",
        "    if pd.isna(screen_str):\n",
        "        return (np.nan, 0, 0, 0)\n",
        "    screen_str = str(screen_str)\n",
        "    is_touchscreen = 1 if 'Touchscreen' in screen_str else 0\n",
        "    is_ips = 1 if 'IPS' in screen_str else 0\n",
        "    is_4k = 1 if '4K' in screen_str or '3840x2160' in screen_str else 0\n",
        "    resolution = re.search(r'(\\d{3,4})\\s*x\\s*(\\d{3,4})', screen_str)\n",
        "    if resolution:\n",
        "        width = int(resolution.group(1))\n",
        "        height = int(resolution.group(2))\n",
        "        total_pixels = width * height\n",
        "    else:\n",
        "        total_pixels = np.nan\n",
        "    return (total_pixels, is_touchscreen, is_ips, is_4k)\n",
        "\n",
        "screen_train = train_processed['ScreenResolution'].apply(extract_screen_features)\n",
        "train_processed['Screen_Pixels'] = [x[0] for x in screen_train]\n",
        "train_processed['Is_Touchscreen'] = [x[1] for x in screen_train]\n",
        "train_processed['Is_IPS'] = [x[2] for x in screen_train]\n",
        "train_processed['Is_4K'] = [x[3] for x in screen_train]\n",
        "\n",
        "screen_test = test_processed['ScreenResolution'].apply(extract_screen_features)\n",
        "test_processed['Screen_Pixels'] = [x[0] for x in screen_test]\n",
        "test_processed['Is_Touchscreen'] = [x[1] for x in screen_test]\n",
        "test_processed['Is_IPS'] = [x[2] for x in screen_test]\n",
        "test_processed['Is_4K'] = [x[3] for x in screen_test]\n",
        "\n",
        "# 5. CPU\n",
        "def extract_cpu_brand(cpu_str):\n",
        "    if pd.isna(cpu_str):\n",
        "        return 'Unknown'\n",
        "    cpu_str = str(cpu_str).upper()\n",
        "    if 'INTEL CORE I7' in cpu_str:\n",
        "        return 'Intel_i7'\n",
        "    elif 'INTEL CORE I5' in cpu_str:\n",
        "        return 'Intel_i5'\n",
        "    elif 'INTEL CORE I3' in cpu_str:\n",
        "        return 'Intel_i3'\n",
        "    elif 'AMD' in cpu_str:\n",
        "        return 'AMD'\n",
        "    elif 'INTEL' in cpu_str:\n",
        "        return 'Intel_Other'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "train_processed['CPU_Brand'] = train_processed['Cpu'].apply(extract_cpu_brand)\n",
        "test_processed['CPU_Brand'] = test_processed['Cpu'].apply(extract_cpu_brand)\n",
        "\n",
        "# 6. GPU\n",
        "def extract_gpu_brand(gpu_str):\n",
        "    if pd.isna(gpu_str):\n",
        "        return 'Unknown'\n",
        "    gpu_str = str(gpu_str).upper()\n",
        "    if 'NVIDIA' in gpu_str or 'GEFORCE' in gpu_str:\n",
        "        return 'Nvidia'\n",
        "    elif 'AMD' in gpu_str or 'RADEON' in gpu_str:\n",
        "        return 'AMD'\n",
        "    elif 'INTEL' in gpu_str:\n",
        "        return 'Intel'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "train_processed['GPU_Brand'] = train_processed['Gpu'].apply(extract_gpu_brand)\n",
        "test_processed['GPU_Brand'] = test_processed['Gpu'].apply(extract_gpu_brand)\n",
        "\n",
        "print(\" Feature Engineering completado\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 3: PREPARAR DATOS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 3: PREPARACI√ìN DE DATOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Features num√©ricas\n",
        "numeric_features = [\n",
        "    'Inches',\n",
        "    'Ram_GB',\n",
        "    'Weight_kg',\n",
        "    'Memory_GB',\n",
        "    'Has_SSD',\n",
        "    'Has_HDD',\n",
        "    'Screen_Pixels',\n",
        "    'Is_Touchscreen',\n",
        "    'Is_IPS',\n",
        "    'Is_4K'\n",
        "]\n",
        "\n",
        "# Features categ√≥ricas\n",
        "categorical_features = [\n",
        "    'Company',\n",
        "    'Product',\n",
        "    'TypeName',\n",
        "    'OpSys',\n",
        "    'CPU_Brand',\n",
        "    'GPU_Brand'\n",
        "]\n",
        "\n",
        "# Label Encoding\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    train_processed[col + '_encoded'] = le.fit_transform(train_processed[col].astype(str))\n",
        "    \n",
        "    def safe_transform(x, encoder):\n",
        "        try:\n",
        "            return encoder.transform([str(x)])[0]\n",
        "        except:\n",
        "            return -1\n",
        "    \n",
        "    test_processed[col + '_encoded'] = test_processed[col].apply(lambda x: safe_transform(x, le))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Features finales\n",
        "categorical_features_encoded = [col + '_encoded' for col in categorical_features]\n",
        "all_features = numeric_features + categorical_features_encoded\n",
        "\n",
        "# Crear datasets\n",
        "X_train = train_processed[all_features].copy()\n",
        "y_train = train_processed['Price_in_euros'].copy()\n",
        "X_test = test_processed[all_features].copy()\n",
        "\n",
        "# Imputar nulos si hay\n",
        "if X_train.isnull().sum().sum() > 0 or X_test.isnull().sum().sum() > 0:\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "    X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "print(f\"\\n Datasets creados:\")\n",
        "print(f\"   X_train: {X_train.shape}\")\n",
        "print(f\"   y_train: {y_train.shape}\")\n",
        "print(f\"   X_test: {X_test.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 4: MODELO LIGHTGBM\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 4: ENTRENAMIENTO DE LIGHTGBM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "model = lgb.LGBMRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    num_leaves=31,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_samples=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "# Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=kf, \n",
        "                             scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
        "cv_rmse = -cv_scores\n",
        "\n",
        "print(f\"\\n CROSS-VALIDATION:\")\n",
        "for i, score in enumerate(cv_rmse, 1):\n",
        "    print(f\"   Fold {i}: {score:.2f}\")\n",
        "print(f\"\\n    RMSE MEDIO: {cv_rmse.mean():.2f} ¬± {cv_rmse.std():.2f}\")\n",
        "\n",
        "# Entrenar con todos los datos\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"\\n Modelo entrenado\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 5: PREDICCIONES\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 5: PREDICCIONES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(f\" Predicciones generadas: {len(predictions)}\")\n",
        "print(f\"   Min: {predictions.min():.2f} ‚Ç¨\")\n",
        "print(f\"   Max: {predictions.max():.2f} ‚Ç¨\")\n",
        "print(f\"   Media: {predictions.mean():.2f} ‚Ç¨\")\n",
        "\n",
        "# Crear submission\n",
        "submission = pd.DataFrame({\n",
        "    'laptop_ID': test_processed['laptop_ID'],\n",
        "    'Price_in_euros': predictions\n",
        "})\n",
        "\n",
        "print(f\"\\n Submission creado: {submission.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 6: VERIFICAR Y GUARDAR\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PASO 6: VERIFICAR Y GUARDAR\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Verificaciones\n",
        "checks_passed = True\n",
        "\n",
        "if submission.shape == sample_submission.shape:\n",
        "    print(f\"    Shape correcto: {submission.shape}\")\n",
        "else:\n",
        "    print(f\"    Shape incorrecto: {submission.shape} vs {sample_submission.shape}\")\n",
        "    checks_passed = False\n",
        "\n",
        "if submission.columns.tolist() == sample_submission.columns.tolist():\n",
        "    print(f\"    Columnas correctas\")\n",
        "else:\n",
        "    print(f\"    Columnas incorrectas\")\n",
        "    checks_passed = False\n",
        "\n",
        "if submission['laptop_ID'].tolist() == sample_submission['laptop_ID'].tolist():\n",
        "    print(f\"    IDs correctos\")\n",
        "else:\n",
        "    print(f\"    IDs no coinciden\")\n",
        "    checks_passed = False\n",
        "\n",
        "if submission.isnull().sum().sum() == 0:\n",
        "    print(f\"    Sin valores nulos\")\n",
        "else:\n",
        "    print(f\"    Hay valores nulos\")\n",
        "    checks_passed = False\n",
        "\n",
        "if checks_passed:\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" ¬°SUBMISSION GUARDADO CORRECTAMENTE!\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"\\n Archivo: submission.csv\")\n",
        "    print(f\" Filas: {len(submission)}\")\n",
        "    print(f\" RMSE esperado: ~{cv_rmse.mean():.2f}\")\n",
        "    print(f\"\\n¬°Listo para subir a Kaggle! üöÄ\")\n",
        "else:\n",
        "    print(f\"\\n Hay errores - Revisar\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
